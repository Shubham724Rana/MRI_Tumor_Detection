# -*- coding: utf-8 -*-
"""MRI Image Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jd9bgpU3xVszF5I4iFHSque6MfzXE5y-

# **# Check current location, '/content/drive/MyDrive/Kaggle'**
Enable the Kaggle environment, use the path to the directory your Kaggle API JSON is stored in
"""

import os
os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/MyDrive/Kaggle'

from google.colab import drive
drive.mount('/content/drive')

"""# Installing Kaggle"""

!pip install kaggle

"""# Changing Directory In Drive

"""

os.chdir('/content/drive/MyDrive/Kaggle/Brain MRI Segmentation')

"""# Downloading The Data Set From Kaggle To Drive"""

!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation

"""#Unzipe the file"""

#unzipe the file
!unzip \*.zip && rm *.zip

"""# Importing Libraries"""

import pandas as pd
import numpy as np
import cv2 as cv
from PIL import Image
import matplotlib.pyplot as plt
import tensorflow as tf
from  keras.preprocessing.image import ImageDataGenerator
from skimage import img_as_float
from skimage.metrics import peak_signal_noise_ratio
from skimage import io
from scipy import ndimage as nd

tf.__version__

dataset = "/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m"

dirs = []
images = []
masks = []
for directory, _, filenames in os.walk(dataset):
    for filename in filenames:
        if 'mask'in filename:
            dirs.append(directory .replace(dataset, ''))
            masks.append(filename)
            images.append(filename.replace('_mask', ''))

path_to_directory = pd.DataFrame(data={'directory':dirs, 'images': images, 'masks': masks})

path_to_directory.info()

"""# MRI Image (Tried on Just One Image without mask)"""

index = np.random.randint(0, len(path_to_directory))
imagePath = "/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/"+os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
image = (cv.imread(imagePath))
plt.imshow(image)

def MRI_Image_Mask():
    index = np.random.randint(0, len(path_to_directory))
    
    imagePath =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
    maskPath = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['masks'].iloc[index])
    image = (cv.imread(imagePath))
    mask = (cv.imread(maskPath))

    fig, axs = plt.subplots(1,3, figsize=[13,15])
    axs[0].imshow(image)
    axs[0].set_title('Brain MRI')
    
    axs[1].imshow(mask)
    axs[1].set_title('Mask')
    
    axs[2].imshow(image)
    axs[2].imshow(mask, alpha=0.3)
    axs[2].set_title('MRI with mask')
    
    plt.grid(False)
    plt.show()

for i in range(100):
  MRI_Image_Mask()

def noise_comparison(ref_image, denoise_image):
  noise_psnr = peak_signal_noise_ratio(ref_image, denoise_image)
  gaussian_cleaned_psnr = peak_signal_noise_ratio(ref_image, denoise_image)
  print("PSNR of Images", gaussian_cleaned_psnr)
  print('\n')

"""# Denoising MRI Images (on a single image)

### Using Gaussian filter
"""

def Gaussian_Denoising():
  index =1778
  print(index)
  imagePath =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
  maskPath = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['masks'].iloc[index])
  image = (cv.imread(imagePath))
  mask = (cv.imread(maskPath))
#Using Gaussian Filter From scipy ndimage and cv2.gaussian filter
  #gaussian_image = nd.gaussian_filter(image , sigma = 1)
  gaussian_image = cv.GaussianBlur(image, (3,3), cv.BORDER_DEFAULT)
  fig, axs = plt.subplots(1,2, figsize=[13,15])
  axs[0].imshow(image)
  axs[0].set_title('Brain MRI Normal')
  axs[1].imshow(gaussian_image)
  axs[1].set_title('Brain MRI Gaussian')
  noise_comparison(image, gaussian_image)
  #plt.subplot(121),plt.imshow(image),plt.title('Original')
  #plt.subplot(122),plt.imshow(gaussian_image),plt.title('Averaging')
  #plt.xticks([]), plt.yticks([])
  #plt.show()
  #plt.imshow("Gaussian Image", gaussian_image)
  #plt.imsave("/content/drive/MyDrive/Kaggle/Modified  MRI Data Base"+imagePath, gaussian_image, cmap = 'gray')

Gaussian_Denoising()

"""## Using Bilateral Filter"""

def Bilateral_Denoising():
  index = 1778
  imagePath =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
  maskPath = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['masks'].iloc[index])
  image = (cv.imread(imagePath))
  mask = (cv.imread(maskPath))
#Using Gaussian Filter  cv2.bilateralFilter()
  bilateral_image = cv.bilateralFilter(image,8,60,60)
  fig, axs = plt.subplots(1,2, figsize=[13,15])
  axs[0].imshow(image)
  axs[0].set_title('Brain MRI Normal')
  axs[1].imshow(bilateral_image)
  axs[1].set_title('Brain MRI Bilateral')
  noise_comparison(image, bilateral_image)

Bilateral_Denoising()

"""## Using Anisotropic Diffusion """

!pip install medpy

from medpy.filter.smoothing import anisotropic_diffusion

def Anisotropic_diffusion():
  index = 1778
  imagePath =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
  maskPath = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['masks'].iloc[index])
  image = img_as_float(io.imread(imagePath,as_gray = True))
  mask = (cv.imread(maskPath))
#Using Anisotropic Diffusion
  img = np.random.uniform(size=(32,32))
  img_filtered = anisotropic_diffusion(image, niter= 50, kappa= 50, gamma= 0.015, option= 2)
  fig, axs = plt.subplots(1,2, figsize=[13,15])
  axs[0].imshow(image)
  axs[0].set_title('Brain MRI Normal')
  axs[1].imshow(img_filtered)
  axs[1].set_title('Brain Anisotropic Diffusion')
  noise_comparison(image, img_filtered)

Anisotropic_diffusion()

"""# **Images Shape And Size**"""

def imageShapeSize():   
    index = np.random.randint(0, len(path_to_directory))  
    imagePath =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['images'].iloc[index])
    maskPath = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m/' + os.path.join(dataset, path_to_directory['directory'].iloc[index], path_to_directory['masks'].iloc[index])
    img = cv.imread(imagePath)
    msk = cv.imread(maskPath)
    height, width, channels = img.shape
    # height, width, number of channels in image
    print('Image Height      : ',height)
    print('Image Width        : ',width)

imageShapeSize()

"""# Data Preprocessing"""

path_to_directory.describe() #rechecking the dataframe

"""# Adding the complete path for the images and masks"""

path_to_directory["imagePath"] = '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m' + path_to_directory["directory"] +'/' + path_to_directory["images"]
path_to_directory["maskPath"] =  '/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m' + path_to_directory["directory"] +'/'+ path_to_directory["masks"]

"""# Data Frame to .csv File"""

path_to_directory.to_csv('MRI_Images_Masks_Paths).csv', encoding='utf-8')

!cp MRI_Images_Masks_Paths.csv "/content/drive/MyDrive/Kaggle/Brain MRI Segmentation"

path_to_directory.head()

len(path_to_directory) #number of elements in directory

"""# paths_df only cantain complete paths of images and masks"""

paths_df = path_to_directory.iloc[:,3:5]

paths_df #data frame

"""# Spliting the data using train test split """

from sklearn.model_selection import train_test_split
train_df , test_df = train_test_split(paths_df, test_size=0.1, random_state=0)

train_df, test_df

IMG_WIDTH = 256
IMG_HEIGHT = 256
IMG_CHANNELS = 3

"""# Data Generator (Augmentation) Keras Img Generator

"""

data_augmentation_parameter = dict(featurewise_center=True,
                        featurewise_std_normalization=True,
                        rotation_range=0.2,
                        width_shift_range=0.05,
                        height_shift_range=0.05,
                        shear_range=0.05,
                        zoom_range=0.05,
                        horizontal_flip=True,
                        fill_mode='nearest')

"""# **Training**  From Keras"""

# image generator
imagegen = ImageDataGenerator(rescale=1./255.) #**data_augmentation_parameter)
maskgen = ImageDataGenerator(rescale=1./255.)#**data_augmentation_parameter)

# train generator
timage_generator=imagegen.flow_from_dataframe(dataframe=train_df,
                                            x_col="imagePath",
                                            batch_size= 32,
                                            seed=42,
                                            class_mode=None,
                                            target_size=(256,256),
                                            color_mode='rgb')
# validation data generator
tmask_generator=maskgen.flow_from_dataframe(dataframe=train_df,
                                            x_col="maskPath",
                                            batch_size=32,
                                            seed=42,
                                            class_mode=None,
                                            target_size=(256,256),
                                            color_mode='grayscale')

"""# Validation Part (here we don't need augmentation)"""

# image generator
imagegen = ImageDataGenerator(rescale=1./255.)
maskgen = ImageDataGenerator(rescale=1./255.)


# train generator
vimage_generator=imagegen.flow_from_dataframe(dataframe=test_df,
                                            x_col="imagePath",
                                            batch_size= 32,
                                            seed=42,
                                            class_mode=None,
                                            target_size=(256,256),
                                            color_mode='rgb')
# validation data generator
vmask_generator=maskgen.flow_from_dataframe(dataframe=test_df,
                                            x_col="maskPath",
                                            batch_size=32,
                                            seed=42,
                                            class_mode=None,
                                            target_size=(256,256),
                                            color_mode='grayscale')

def data_iterator(image_gen, mask_gen):
    for img, mask in zip(image_gen, mask_gen):
        yield img, mask

train_gen = data_iterator(timage_generator, tmask_generator)
valid_gen = data_iterator(vimage_generator, vmask_generator)

train_gen, valid_gen

"""# Method For Image Augmnetation"""

def train_generator(data_frame, batch_size, aug_dict,
        image_color_mode="rgb",
        mask_color_mode="grayscale",
        image_save_prefix="image",
        mask_save_prefix="mask",
        save_to_dir=None,
        target_size=(256,256),
        seed=42):
    
    image_datagen = ImageDataGenerator(**aug_dict)
    mask_datagen = ImageDataGenerator(**aug_dict)
    
    image_generator = image_datagen.flow_from_dataframe(
        data_frame,
        x_col = "imagePath",
        class_mode = None,
        color_mode = image_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = image_save_prefix,
        seed = seed)

    mask_generator = mask_datagen.flow_from_dataframe(
        data_frame,
        x_col = "maskPath",
        class_mode = None,
        color_mode = mask_color_mode,
        target_size = target_size,
        batch_size = batch_size,
        save_to_dir = save_to_dir,
        save_prefix  = mask_save_prefix,
        seed = seed)
    
    train_gen = zip(image_generator, mask_generator)
    
    for (img, mask) in train_gen:
        img, mask = adjust_data(img, mask)
        yield (img, mask)
    
        
def adjust_data(img, mask):
    img = img / 255
    mask = mask / 255
    mask[mask > 0.5] = 1
    mask[mask <= 0.5] = 0
    
    return (img, mask)

train_gen = train_generator(train_df, 32, data_augmentation_parameter)

train_gen

"""# Image Segmentation using U-Net"""

import tensorflow as  tf
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda
from keras.optimizers import Adam
from keras.metrics import MeanIoU

"""# **Simple Unet Model Trained Model 1**"""

#lets define image dimensions
IMG_WIDTH = 256
IMG_HEIGHT = 256
IMG_CHANNELS = 3

def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS):
#Build the model
    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
    kernel_initializer =  'he_uniform'  # also try 'he_normal' but model not converging... 
    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand
    s = inputs

    #Contraction path
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)
    c1 = Dropout(0.1)(c1)
    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)
    p1 = MaxPooling2D((2, 2))(c1)
    
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)
    c2 = Dropout(0.1)(c2)
    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)
    p2 = MaxPooling2D((2, 2))(c2)
     
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)
    c3 = Dropout(0.2)(c3)
    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)
    p3 = MaxPooling2D((2, 2))(c3)
     
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)
    c4 = Dropout(0.2)(c4)
    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)
    p4 = MaxPooling2D(pool_size=(2, 2))(c4)
     
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)
    c5 = Dropout(0.3)(c5)
    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)
    
    #Expansive path 
    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
    u6 = concatenate([u6, c4])
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)
    c6 = Dropout(0.2)(c6)
    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)
     
    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
    u7 = concatenate([u7, c3])
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)
    c7 = Dropout(0.2)(c7)
    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)
     
    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
    u8 = concatenate([u8, c2])
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)
    c8 = Dropout(0.1)(c8)
    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)
     
    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
    u9 = concatenate([u9, c1], axis=3)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)
    c9 = Dropout(0.1)(c9)
    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)
     
    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)
     
    model = Model(inputs=[inputs], outputs=[outputs])
    model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=['accuracy'])
    #model.compile(optimizer=Adam(lr = 1e-3), loss='binary_crossentropy', metrics=[MeanIoU(num_classes=2)])
    model.summary()
    
    return model

model = simple_unet_model(256, 256, 3)
model.compile(optimizer= 'adam', loss="binary_crossentropy", metrics=["accuracy"])

#model check point
checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_MRI.h5',verbose= 1, save_best_only= True)
#classback
callbacks = [tf.keras.callbacks.EarlyStopping(patience= 2, monitor= 'val_loss'),
             tf.keras.callbacks.TensorBoard(log_dir= 'logs')]

STEP_SIZE_TRAIN = timage_generator.n/20
STEP_SIZE_VALID = vimage_generator.n/20

results = model.fit(train_gen,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    batch_size= 6,
                    epochs=25,
                    callbacks=callbacks,
                    validation_data=valid_gen,
                   validation_steps=STEP_SIZE_VALID)

"""# Saving Model"""

model.save("/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/Saved Model/MRI_IS_Model_1.h5")

"""# Testing Trained Model 1 (model predictions)



"""

#Random index
import random
index = random.randint(0, len(test_df))

image_train = tf.keras.preprocessing.image.load_img(train_df['imagePath'][index])
input_arr_train = tf.keras.preprocessing.image.img_to_array(image)
input_arr_train = np.array([input_arr])  # Convert single image to a batch.
predictions_train = model.predict(input_arr)

image_test = tf.keras.preprocessing.image.load_img('/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/Train, Test, Validation/val/TCGA_CS_4941_19960909/TCGA_CS_4941_19960909_12.tif')
input_arr_test = tf.keras.preprocessing.image.img_to_array(image)
input_arr_test = np.array([input_arr])  # Convert single image to a batch.
predictions_test = model.predict(input_arr)

preds_train = (predictions_train > 0.5).astype(np.uint8)
preds_test = (predictions_test > 0.5).astype(np.uint8)

"""# Perform a sanity check on some random images"""

# load the best model
model.load_weights('/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/Saved Model/MRI_IS_Model_1.h5')

eval_results = model.evaluate(valid_gen, steps=STEP_SIZE_VALID, verbose=1)

DataPath = "/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m"

idx = np.random.randint(0, len(path_to_directory))
imagePath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['images'].iloc[idx])
maskPath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['masks'].iloc[idx])

imagePath

for i in range(30):
    idx = np.random.randint(0, len(path_to_directory))
    imagePath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['images'].iloc[idx])
    maskPath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['masks'].iloc[idx])
        
    image = (cv.imread(imagePath))
    mask = (cv.imread(maskPath))
    
    img = cv.resize(image, (256, 256), interpolation=cv.INTER_AREA)
    img = img / 255
    img = img[np.newaxis, :, :, :]
    pred=model.predict(img)

    plt.figure(figsize=(12,12))
    plt.subplot(1,4,1)
    plt.imshow(np.squeeze(img))
    plt.title('Original Image')
    plt.subplot(1,4,2)
    plt.imshow(mask)
    plt.title('Original Mask')
    plt.subplot(1,4,3)
    plt.imshow(np.squeeze(pred))
    plt.title('Prediction')
    plt.subplot(1,4,4)
    plt.imshow(np.squeeze(pred) > 0.5)
    plt.title('BinaryPrediction')
    plt.show()

"""# Building the Model using keras model Trained Model 2"""

inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))

"""# Defining Conv Layers"""

s = tf.keras.layers.Lambda(lambda x: x / 255)(inputs) # floation values
c1 = tf.keras.layers.Conv2D(16, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(inputs)
#kernel_initializer for initial waits he_normal is centred about 0 all the weights around the zeros
#paddind as we are using conv2d 3x3 so it will effect the boundary\edge pixel so we add extra pixels so output and input remain same
c1 = tf.keras.layers.Dropout(0.1)(c1) #10% dropout to avoid overfitting
c1 = tf.keras.layers.Conv2D(16, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(c1)
p1 = tf.keras.layers.MaxPool2D((2,2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(p1)
c2 = tf.keras.layers.Dropout(0.1)(c2) #10%  dropout
c2 = tf.keras.layers.Conv2D(32, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(c2)
p2 = tf.keras.layers.MaxPool2D((2,2))(c2)

c3 = tf.keras.layers.Conv2D(64, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3) #20% dropout
c3 = tf.keras.layers.Conv2D(64, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(c3)
p3 = tf.keras.layers.MaxPool2D((2,2))(c3)

c4 = tf.keras.layers.Conv2D(128, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4) #20% dropout
c4 = tf.keras.layers.Conv2D(128, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(c4)
p4 = tf.keras.layers.MaxPool2D((2,2))(c4)


c5 = tf.keras.layers.Conv2D(256, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5) #30% dropout
c5 = tf.keras.layers.Conv2D(256, (3,3), activation= 'relu', kernel_initializer='he_normal', padding= 'same')(c5)

#Upsampling/ Expansive path

u6 = tf.keras.layers.Conv2DTranspose(128,(2,2), strides=(2,2), padding= 'same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(c6)

u7 = tf.keras.layers.Conv2DTranspose(64,(2,2), strides=(2,2), padding= 'same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(c7)

u8 = tf.keras.layers.Conv2DTranspose(32,(2,2), strides=(2,2), padding= 'same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
c8 = tf.keras.layers.Conv2D(32, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(c8)


u9 = tf.keras.layers.Conv2DTranspose(16,(2,2), strides=(2,2), padding= 'same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1])
c9 = tf.keras.layers.Conv2D(16, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
c9 = tf.keras.layers.Conv2D(16, ( 3, 3), activation= 'relu', kernel_initializer= 'he_normal', padding= 'same')(c9)

#output layer
outputs = tf.keras.layers.Conv2D(1, (1, 1), activation= 'sigmoid')(c9)

#model
model = tf.keras.Model(inputs=[inputs], outputs= [outputs])
model.compile(optimizer="adam", loss= 'binary_crossentropy', metrics= ['accuracy'])

"""# Summary of layers in our model"""

model.summary()

"""# Fitting The Model (setting check points and callbacks)"""

#model check point
checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_MRI.h5',verbose= 1, save_best_only= True)
#classback
callbacks = [tf.keras.callbacks.EarlyStopping(patience= 2, monitor= 'val_loss'),
             tf.keras.callbacks.TensorBoard(log_dir= 'logs')]
results = model.fit(train_gen, validation_data= valid_gen, batch_size= 32, epochs= 25, callbacks= callbacks)

"""# **U-NET Train Model 3**

# Improvment

*   Batch Normalisation- elongated loss is problem so it help to (subtract mean and dividing SD as we know so using this we can use larger learning rates as previous it was problem. ) And cost Fuction is  symmetric type and evenly spread, Its also act as regularisation. It increase speed
*  Adam Learning Rate Optimizer (LRO) can be used for adaptive learning rate optimizer as different feature will have different learning rates.
"""

def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):
    """Function to add 2 convolutional layers with the parameters passed to it"""
    # first layer
    x =  tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
               kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x =  tf.keras.layers.BatchNormalization()(x)
    x =  tf.keras.layers.Activation('relu')(x)
    
    # second layer
    x =  tf.keras.layers.Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\
              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)
    if batchnorm:
        x =  tf.keras.layers.BatchNormalization()(x)
    x =  tf.keras.layers.Activation('relu')(x)
    
    return x

def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):
    """Function to define the UNET Model"""
    # Contracting Path
    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)
    p1 = tf.keras.layers.Dropout(dropout)(p1)
    
    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)
    p2 = tf.keras.layers.Dropout(dropout)(p2)
    
    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)
    p3 = tf.keras.layers.Dropout(dropout)(p3)
    
    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)
    p4 = tf.keras.layers.Dropout(dropout)(p4)
    
    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)
    
    # Expansive Path
    u6 = tf.keras.layers.Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)
    u6 = tf.keras.layers.concatenate([u6, c4])
    u6 = tf.keras.layers.Dropout(dropout)(u6)
    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)
    
    u7 = tf.keras.layers.Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)
    u7 = tf.keras.layers.concatenate([u7, c3])
    u7 = tf.keras.layers.Dropout(dropout)(u7)
    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)
    
    u8 = tf.keras.layers.Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)
    u8 = tf.keras.layers.concatenate([u8, c2])
    u8 = tf.keras.layers.Dropout(dropout)(u8)
    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)
    
    u9 = tf.keras.layers.Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)
    u9 = tf.keras.layers.concatenate([u9, c1])
    u9 = tf.keras.layers.Dropout(dropout)(u9)
    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)
    
    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)
    model = tf.keras.Model(inputs=[input_img], outputs=[outputs])
    return model

input_img = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), name='img')
model3 = get_unet(input_img, n_filters=16, dropout=0.2, batchnorm=True)
model3.compile(optimizer='adam', loss="binary_crossentropy", metrics=["accuracy"])

model3.summary()

#model check point
checkpointer = tf.keras.callbacks.ModelCheckpoint('model_for_MRI.h5',verbose= 1, save_best_only= True)
#classback
callbacks = [tf.keras.callbacks.EarlyStopping(patience= 2, monitor= 'val_loss'),
             tf.keras.callbacks.TensorBoard(log_dir= 'logs')]

STEP_SIZE_TRAIN = timage_generator.n/20
STEP_SIZE_VALID = vimage_generator.n/20

results = model3.fit(train_gen,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    batch_size= 6,
                    epochs=25,
                    callbacks=callbacks,
                    validation_data=valid_gen,
                   validation_steps=STEP_SIZE_VALID)

model3.save('/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/Saved Model/MRI_IS_Model3_Batch_Nornalisation.h5')

# load the best model
model3.load_weights('/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/Saved Model/MRI_IS_Model3_Batch_Nornalisation.h5')

eval_results = model3.evaluate(valid_gen, steps=STEP_SIZE_VALID, verbose=1)

DataPath = "/content/drive/MyDrive/Kaggle/Brain MRI Segmentation/kaggle_3m"

idx = np.random.randint(0, len(path_to_directory))
imagePath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['images'].iloc[idx])
maskPath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['masks'].iloc[idx])

for i in range(30):
    idx = np.random.randint(0, len(path_to_directory))
    imagePath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['images'].iloc[idx])
    maskPath = DataPath + os.path.join(DataPath, path_to_directory['directory'].iloc[idx], path_to_directory['masks'].iloc[idx])
        
    image = (cv.imread(imagePath))
    mask = (cv.imread(maskPath))
    
    img = cv.resize(image, (256, 256), interpolation=cv.INTER_AREA)
    img = img / 255
    img = img[np.newaxis, :, :, :]
    pred=model3.predict(img)

    plt.figure(figsize=(12,12))
    plt.subplot(1,4,1)
    plt.imshow(np.squeeze(img))
    plt.title('Original Image')
    plt.subplot(1,4,2)
    plt.imshow(mask)
    plt.title('Original Mask')
    plt.subplot(1,4,3)
    plt.imshow(np.squeeze(pred))
    plt.title('Prediction')
    plt.subplot(1,4,4)
    plt.imshow(np.squeeze(pred) > 0.5)
    plt.title('BinaryPrediction')
    plt.show()

